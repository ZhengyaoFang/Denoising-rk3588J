import os
import time
import cv2
import numpy as np
import multiprocessing as mp
from tqdm import tqdm
from hailo_platform import (
    HEF,
    ConfigureParams,
    Device,
    FormatType,
    HailoSchedulingAlgorithm,
    HailoStreamInterface,
    InferVStreams,
    InputVStreamParams,
    OutputVStreamParams,
    VDevice,
)

# -------------------------- æ ¸å¿ƒé…ç½®å‚æ•° --------------------------
# æ‘„åƒå¤´å‚æ•°
CAMERA_DEVICE_PATH = "/dev/video21"  # æ‘„åƒå¤´è®¾å¤‡è·¯å¾„ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
TARGET_RESOLUTION = (960, 720)       # ç›®æ ‡åˆ†è¾¨ç‡ (width, height)
TARGET_FPS = 60                      # ç›®æ ‡å¸§ç‡
VIDEO_FORMAT = cv2.VideoWriter_fourcc(*"MJPG")  # æ‘„åƒå¤´æ ¼å¼ï¼ˆMJPGæ”¯æŒé«˜å¸§ç‡ï¼‰

# æ¨ç†å‚æ•°
HEF_PATH = "/home/firefly/Denoising-rk3588J/models/dncnn_v0/dncnn_bs3.hef"  # Hailoæ¨¡å‹è·¯å¾„
BATCH_SIZE = 2                        # å•è®¾å¤‡æ‰¹æ¬¡å¤§å°ï¼ˆå¹³è¡¡å®æ—¶æ€§ä¸æ•ˆç‡ï¼‰
INPUT_SHAPE = (3, 720, 960)          # æ¨¡å‹è¾“å…¥å½¢çŠ¶ (channel, height, width)
NUM_DEVICES = 2                       # å¯ç”¨çš„HailoåŠ é€Ÿæ£’æ•°é‡
QUEUE_MAX_SIZE = 50                   # ä»»åŠ¡é˜Ÿåˆ—æœ€å¤§ç¼“å­˜ï¼ˆé¿å…å¸§å †ç§¯ï¼‰
RUN_DURATION = 10                     # æµ‹è¯•è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼Œå¯ä¿®æ”¹ï¼‰

# -------------------------- å¸§é¢„å¤„ç†ï¼ˆé€‚é…æ‘„åƒå¤´è¾“å…¥ï¼‰ --------------------------
def process_frame(frame):
    """
    å¤„ç†æ‘„åƒå¤´BGRå¸§ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ï¼ˆRGB+CHW+float32ï¼‰
    :param frame: cv2è¯»å–çš„BGRå¸§ï¼ˆHWCæ ¼å¼ï¼‰
    :return: é¢„å¤„ç†åçš„æ•°æ®ï¼ˆCHWæ ¼å¼ï¼‰ã€é¢„å¤„ç†è€—æ—¶
    """
    start_time = time.time()
    
    # 1. BGRè½¬RGBï¼ˆcv2é»˜è®¤BGRï¼Œæ¨¡å‹éœ€è¦RGBï¼‰
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # 2. è°ƒæ•´åˆ†è¾¨ç‡ï¼ˆç¡®ä¿ä¸ç›®æ ‡ä¸€è‡´ï¼Œé˜²æ­¢æ‘„åƒå¤´å‚æ•°è®¾ç½®å¤±æ•ˆï¼‰
    frame_resized = cv2.resize(
        frame_rgb, 
        dsize=TARGET_RESOLUTION, 
        interpolation=cv2.INTER_LANCZOS4  # é«˜è´¨é‡æ’å€¼ï¼ˆä¸åŸä»£ç PIL.LANCZOSå¯¹åº”ï¼‰
    )
    
    # 3. æ ¼å¼è½¬æ¢ï¼šHWC -> CHWï¼Œ dtype -> float32
    frame_chw = frame_resized.transpose(2, 0, 1)  # (H,W,C) â†’ (C,H,W)
    frame_float = frame_chw.astype(np.float32)
    
    process_time = time.time() - start_time
    return frame_float, process_time

# -------------------------- è®¾å¤‡åˆå§‹åŒ–ï¼ˆå¤ç”¨åŸæ¨ç†é€»è¾‘ï¼‰ --------------------------
def init_device(hef_path, device_id):
    """åˆå§‹åŒ–å•ä¸ªHailoè®¾å¤‡å¹¶åŠ è½½æ¨¡å‹ï¼Œä¸åŸæ¨ç†ä»£ç é€»è¾‘ä¸€è‡´"""
    device_ids = Device.scan()
    if len(device_ids) <= device_id:
        raise RuntimeError(f"è®¾å¤‡ID {device_id} ä¸å­˜åœ¨ï¼Œä»…æ£€æµ‹åˆ° {len(device_ids)} ä¸ªè®¾å¤‡")
    
    print(f"åˆå§‹åŒ–è®¾å¤‡ {device_id}ï¼ˆç¡¬ä»¶ID: {device_ids[device_id]}ï¼‰...")
    
    # åˆ›å»ºè®¾å¤‡å‚æ•°ï¼ˆPCIeæ¥å£ï¼‰
    vdevice_params = VDevice.create_params()
    vdevice_params.scheduling_algorithm = HailoSchedulingAlgorithm.NONE
    vdevice_params.device_ids.append(device_id)
    target = VDevice(params=vdevice_params)
    
    # åŠ è½½HEFæ¨¡å‹
    hef = HEF(hef_path)
    
    # é…ç½®ç½‘ç»œç»„
    configure_params = ConfigureParams.create_from_hef(hef=hef, interface=HailoStreamInterface.PCIe)
    network_groups = target.configure(hef, configure_params)
    network_group = network_groups[0]
    network_group_params = network_group.create_params()
    
    # åˆ›å»ºè¾“å…¥/è¾“å‡ºæµå‚æ•°ï¼ˆè¾“å…¥float32ï¼Œè¾“å‡ºuint8ï¼‰
    input_vstreams_params = InputVStreamParams.make(network_group, quantized=False, format_type=FormatType.FLOAT32)
    output_vstreams_params = OutputVStreamParams.make(network_group, quantized=True, format_type=FormatType.UINT8)
    
    # è·å–æµä¿¡æ¯
    input_vstream_info = hef.get_input_vstream_infos()[0]
    output_vstream_info = hef.get_output_vstream_infos()[0]
    
    device_info = {
        "target": target,
        "hef": hef,
        "network_group": network_group,
        "network_group_params": network_group_params,
        "input_vstreams_params": input_vstreams_params,
        "output_vstreams_params": output_vstreams_params,
        "input_vstream_info": input_vstream_info,
        "output_vstream_info": output_vstream_info,
        "device_id": device_id
    }
    
    print(f"è®¾å¤‡ {device_id} åˆå§‹åŒ–å®Œæˆ | è¾“å…¥å½¢çŠ¶: {input_vstream_info.shape} | è¾“å‡ºå½¢çŠ¶: {output_vstream_info.shape}")
    return device_info

# -------------------------- æ¨ç†å‡½æ•°ï¼ˆå¤ç”¨åŸé€»è¾‘ï¼‰ --------------------------
def run_inference(device, input_batch):
    """åœ¨å•ä¸ªè®¾å¤‡ä¸Šè¿è¡Œæ¨ç†ï¼Œè¿”å›æ¨ç†ç»“æœä¸è€—æ—¶"""
    network_group = device["network_group"]
    input_vstreams_params = device["input_vstreams_params"]
    output_vstreams_params = device["output_vstreams_params"]
    network_group_params = device["network_group_params"]
    input_vstream_info = device["input_vstream_info"]
    
    start_time = time.time()
    with InferVStreams(network_group, input_vstreams_params, output_vstreams_params) as infer_pipeline:
        with network_group.activate(network_group_params):
            input_data = {input_vstream_info.name: input_batch}
            infer_results = infer_pipeline.infer(input_data)
    
    inference_time = time.time() - start_time
    output_tensor = infer_results[device["output_vstream_info"].name]
    return output_tensor, inference_time

# -------------------------- å·¥ä½œè¿›ç¨‹ï¼ˆç§»é™¤å›¾åƒä¿å­˜ï¼Œä¸“æ³¨æ¨ç†ï¼‰ --------------------------
def worker_process(device_id, task_queue, result_queue, hef_path):
    """
    è®¾å¤‡å·¥ä½œè¿›ç¨‹ï¼šæ¥æ”¶æ‘„åƒå¤´å¸§æ‰¹æ¬¡ â†’ æ¨ç† â†’ è¿”å›ç»“æœï¼ˆæ— å›¾åƒä¿å­˜ï¼‰
    :param task_queue: ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå…ƒç´ ï¼š(batch_tensor, actual_batch_size, batch_index)ï¼‰
    :param result_queue: ç»“æœé˜Ÿåˆ—ï¼ˆå…ƒç´ ï¼š(batch_index, actual_batch_size, infer_time)ï¼‰
    """
    try:
        device = init_device(hef_path, device_id)
        print(f"è®¾å¤‡ {device_id} å·¥ä½œè¿›ç¨‹å¯åŠ¨ï¼ˆPID: {os.getpid()}ï¼‰")
        
        while True:
            task = task_queue.get()
            if task is None:  # ç»ˆæ­¢ä¿¡å·
                break
            
            batch_tensor, actual_batch_size, batch_index = task
            # æ‰§è¡Œæ¨ç†ï¼ˆå¿½ç•¥è¾“å‡ºç»“æœï¼Œä»…ç»Ÿè®¡æ—¶é—´ï¼‰
            _, infer_time = run_inference(device, batch_tensor)
            # å‘ä¸»è¿›ç¨‹è¿”å›ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ‰¹æ¬¡ç´¢å¼•ã€å®é™…æœ‰æ•ˆå¸§æ•°ã€æ¨ç†è€—æ—¶ï¼‰
            result_queue.put((batch_index, actual_batch_size, infer_time))
    
    except Exception as e:
        print(f"è®¾å¤‡ {device_id} å·¥ä½œè¿›ç¨‹å‡ºé”™: {str(e)}")
    finally:
        # é‡Šæ”¾è®¾å¤‡èµ„æº
        if "device" in locals():
            device["target"].release()
        print(f"è®¾å¤‡ {device_id} å·¥ä½œè¿›ç¨‹é€€å‡º")

# -------------------------- ä¸»æµç¨‹ï¼ˆæ‘„åƒå¤´è¯»å–+å®æ—¶æ¨ç†+FPSç»Ÿè®¡ï¼‰ --------------------------
def main():
    total_start_time = time.time()
    print("="*60)
    print(f"å¼€å§‹å®æ—¶æ¨ç†æµ‹è¯• | ç›®æ ‡: {TARGET_RESOLUTION[0]}Ã—{TARGET_RESOLUTION[1]} @ {TARGET_FPS}fps | è¿è¡Œæ—¶é•¿: {RUN_DURATION}s")
    print(f"è®¾å¤‡æ•°é‡: {NUM_DEVICES} | æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} | æ¨¡å‹è·¯å¾„: {HEF_PATH}")
    print("="*60)

    # -------------------------- 1. åˆå§‹åŒ–è¿›ç¨‹ä¸é˜Ÿåˆ— --------------------------
    # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ¯ä¸ªè®¾å¤‡ä¸€ä¸ªï¼‰ï¼šç¼“å­˜å¾…æ¨ç†çš„å¸§æ‰¹æ¬¡
    task_queues = [mp.Queue(maxsize=QUEUE_MAX_SIZE) for _ in range(NUM_DEVICES)]
    # ç»“æœé˜Ÿåˆ—ï¼šæ¥æ”¶æ¨ç†ç»Ÿè®¡ä¿¡æ¯
    result_queue = mp.Queue()
    
    # å¯åŠ¨å·¥ä½œè¿›ç¨‹
    processes = []
    for device_id in range(NUM_DEVICES):
        p = mp.Process(
            target=worker_process,
            args=(device_id, task_queues[device_id], result_queue, HEF_PATH)
        )
        p.start()
        processes.append(p)
    time.sleep(2)  # ç­‰å¾…è®¾å¤‡åˆå§‹åŒ–å®Œæˆ

    # -------------------------- 2. åˆå§‹åŒ–æ‘„åƒå¤´ --------------------------
    cap = cv2.VideoCapture(CAMERA_DEVICE_PATH)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´è®¾å¤‡: {CAMERA_DEVICE_PATH}")
    
    # è®¾ç½®æ‘„åƒå¤´å‚æ•°ï¼ˆMJPGæ ¼å¼æ”¯æŒé«˜å¸§ç‡ï¼‰
    cap.set(cv2.CAP_PROP_FOURCC, VIDEO_FORMAT)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, TARGET_RESOLUTION[0])
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, TARGET_RESOLUTION[1])
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
    
    # éªŒè¯å‚æ•°æ˜¯å¦è®¾ç½®æˆåŠŸï¼ˆéƒ¨åˆ†æ‘„åƒå¤´å¯èƒ½ä¸æ”¯æŒç›®æ ‡é…ç½®ï¼‰
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    actual_fps = cap.get(cv2.CAP_PROP_FPS)
    print(f"\næ‘„åƒå¤´å‚æ•°éªŒè¯ | å®é™…åˆ†è¾¨ç‡: {actual_width}Ã—{actual_height} | å®é™…å¸§ç‡: {actual_fps:.1f}fps")
    if (actual_width, actual_height) != TARGET_RESOLUTION:
        print(f"âš ï¸  æ‘„åƒå¤´ä¸æ”¯æŒ {TARGET_RESOLUTION[0]}Ã—{TARGET_RESOLUTION[1]}ï¼Œå°†ä½¿ç”¨å®é™…åˆ†è¾¨ç‡ {actual_width}Ã—{actual_height}")

    # -------------------------- 3. åˆå§‹åŒ–ç»Ÿè®¡å˜é‡ --------------------------
    read_total_frames = 0          # æ‘„åƒå¤´è¯»å–çš„æ€»å¸§æ•°
    infer_total_frames = 0         # æˆåŠŸæ¨ç†çš„æ€»å¸§æ•°
    read_start_time = time.time()  # æ‘„åƒå¤´è¯»å–å¼€å§‹æ—¶é—´
    infer_start_time = None        # æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡å‘é€æ—¶è®°å½•ï¼‰
    total_infer_compute_time = 0   # æ¨ç†è®¡ç®—æ€»è€—æ—¶ï¼ˆæ‰€æœ‰è®¾å¤‡ç´¯åŠ ï¼‰
    batch_index = 0                # æ‰¹æ¬¡ç´¢å¼•ï¼ˆç”¨äºåŒ¹é…ä»»åŠ¡ä¸ç»“æœï¼‰
    device_buffers = [[] for _ in range(NUM_DEVICES)]  # å„è®¾å¤‡çš„å¸§ç¼“å­˜ï¼ˆç§¯ç´¯æ‰¹æ¬¡ï¼‰

    # -------------------------- 4. å®æ—¶è¯»å–+æ¨ç†å¾ªç¯ --------------------------
    print(f"\nå¼€å§‹è¯»å–æ‘„åƒå¤´å¸§ï¼ˆæŒ‰ 'q' æå‰é€€å‡ºï¼‰...")
    while (time.time() - read_start_time) < RUN_DURATION:
        # è¯»å–æ‘„åƒå¤´å¸§
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸  æ— æ³•è¯»å–æ‘„åƒå¤´å¸§ï¼Œé€€å‡ºå¾ªç¯")
            break
        
        read_total_frames += 1
        current_time = time.time()

        # é¢„å¤„ç†å¸§ï¼ˆBGRâ†’RGBâ†’CHWâ†’float32ï¼‰
        frame_processed, _ = process_frame(frame)

        # åˆ†é…å¸§åˆ°è®¾å¤‡ç¼“å­˜ï¼ˆè½®è¯¢åˆ†é…ï¼Œå‡è¡¡è´Ÿè½½ï¼‰
        target_device_id = read_total_frames % NUM_DEVICES
        device_buffers[target_device_id].append(frame_processed)

        # å½“ç¼“å­˜è¾¾åˆ°æ‰¹æ¬¡å¤§å°æ—¶ï¼Œå‘é€æ¨ç†ä»»åŠ¡
        if len(device_buffers[target_device_id]) >= BATCH_SIZE:
            # æå–æ‰¹æ¬¡å¸§å¹¶è¡¥é›¶ï¼ˆä¸è¶³æ‰¹æ¬¡å¤§å°æ—¶ï¼‰
            batch_frames = device_buffers[target_device_id][:BATCH_SIZE]
            actual_batch_size = len(batch_frames)
            if actual_batch_size < BATCH_SIZE:
                pad_size = BATCH_SIZE - actual_batch_size
                batch_frames += [np.zeros_like(batch_frames[0]) for _ in range(pad_size)]
            
            # è½¬æ¢ä¸ºæ‰¹æ¬¡å¼ é‡ï¼ˆshape: [batch_size, C, H, W]ï¼‰
            batch_tensor = np.stack(batch_frames, axis=0)

            # å‘é€ä»»åŠ¡åˆ°é˜Ÿåˆ—ï¼ˆé¿å…é˜Ÿåˆ—æ»¡å¯¼è‡´é˜»å¡ï¼‰
            try:
                task_queues[target_device_id].put(
                    (batch_tensor, actual_batch_size, batch_index),
                    block=False  # éé˜»å¡æ¨¡å¼ï¼Œé˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒ
                )
                batch_index += 1
                # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç¬¬ä¸€ä¸ªä»»åŠ¡å‘é€æ—¶ï¼‰
                if infer_start_time is None:
                    infer_start_time = current_time
                print(f"ğŸ“¤ è®¾å¤‡ {target_device_id} å‘é€æ‰¹æ¬¡ {batch_index-1}ï¼ˆæœ‰æ•ˆå¸§: {actual_batch_size}ï¼‰", end="\r")
            except mp.Queue.Full:
                print(f"âš ï¸  è®¾å¤‡ {target_device_id} ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå½“å‰æ‰¹æ¬¡", end="\r")

            # æ¸…ç©ºå·²å‘é€çš„ç¼“å­˜
            device_buffers[target_device_id] = device_buffers[target_device_id][BATCH_SIZE:]

        # æŒ‰ 'q' é”®æå‰é€€å‡º
        if cv2.waitKey(1) & 0xFF == ord("q"):
            print("\nğŸ›‘ ç”¨æˆ·æŒ‰ä¸‹ 'q' é”®ï¼Œæå‰é€€å‡º")
            break

    # -------------------------- 5. å¤„ç†å‰©ä½™å¸§ï¼ˆç¼“å­˜ä¸­æœªå‘é€çš„å¸§ï¼‰ --------------------------
    print(f"\n\nå¤„ç†ç¼“å­˜ä¸­å‰©ä½™çš„å¸§...")
    for device_id in range(NUM_DEVICES):
        remaining_frames = device_buffers[device_id]
        if len(remaining_frames) == 0:
            continue
        
        # å¤„ç†å‰©ä½™å¸§ï¼ˆä¸è¶³æ‰¹æ¬¡å¤§å°æ—¶è¡¥é›¶ï¼‰
        actual_batch_size = len(remaining_frames)
        if actual_batch_size < BATCH_SIZE:
            pad_size = BATCH_SIZE - actual_batch_size
            remaining_frames += [np.zeros_like(remaining_frames[0]) for _ in range(pad_size)]
        
        batch_tensor = np.stack(remaining_frames, axis=0)
        try:
            task_queues[device_id].put((batch_tensor, actual_batch_size, batch_index), block=True, timeout=5)
            batch_index += 1
            print(f"ğŸ“¤ è®¾å¤‡ {device_id} å‘é€å‰©ä½™æ‰¹æ¬¡ {batch_index-1}ï¼ˆæœ‰æ•ˆå¸§: {actual_batch_size}ï¼‰")
        except mp.Queue.Full:
            print(f"âš ï¸  è®¾å¤‡ {device_id} é˜Ÿåˆ—æ»¡ï¼Œæ— æ³•å‘é€å‰©ä½™ {actual_batch_size} å¸§")

    # -------------------------- 6. å‘é€ç»ˆæ­¢ä¿¡å·å¹¶æ”¶é›†ç»“æœ --------------------------
    # å‘æ‰€æœ‰å·¥ä½œè¿›ç¨‹å‘é€ç»ˆæ­¢ä¿¡å·
    for q in task_queues:
        q.put(None)
    
    # æ”¶é›†æ¨ç†ç»“æœï¼ˆè¿›åº¦æ¡æ˜¾ç¤ºï¼‰
    print(f"\næ”¶é›†æ¨ç†ç»“æœ...")
    processed_batches = 0
    progress_bar = tqdm(total=batch_index, desc="æ¨ç†è¿›åº¦")
    while processed_batches < batch_index:
        try:
            # ä»ç»“æœé˜Ÿåˆ—è·å–æ•°æ®ï¼ˆé˜»å¡ç­‰å¾…ï¼‰
            batch_idx, actual_frames, infer_time = result_queue.get(block=True, timeout=30)
            infer_total_frames += actual_frames
            total_infer_compute_time += infer_time
            processed_batches += 1
            progress_bar.update(1)
        except mp.Queue.Empty:
            print(f"âš ï¸  ç»“æœé˜Ÿåˆ—è¶…æ—¶ï¼Œæœªæ”¶é›†åˆ°æ‰€æœ‰æ‰¹æ¬¡ç»“æœï¼ˆå·²å¤„ç† {processed_batches}/{batch_index}ï¼‰")
            break
    progress_bar.close()

    # -------------------------- 7. é‡Šæ”¾èµ„æº --------------------------
    cap.release()
    cv2.destroyAllWindows()
    for p in processes:
        p.join(timeout=10)
        print(f"ğŸ”š è®¾å¤‡è¿›ç¨‹ {p.pid} é€€å‡ºçŠ¶æ€: {'æ­£å¸¸' if p.exitcode == 0 else 'å¼‚å¸¸'}")

    # -------------------------- 8. è®¡ç®—å¹¶è¾“å‡ºFPSç»Ÿè®¡ --------------------------
    print("\n" + "="*60)
    print("ğŸ“Š å®æ—¶æ¨ç†FPSç»Ÿè®¡ç»“æœ")
    print("="*60)

    # 1. æ‘„åƒå¤´è¯»å–æ€§èƒ½
    read_total_time = time.time() - read_start_time
    read_fps = read_total_frames / read_total_time if read_total_time > 1e-3 else 0.0
    print(f"1. æ‘„åƒå¤´è¯»å–æ€§èƒ½")
    print(f"   - æ€»è¯»å–å¸§æ•°: {read_total_frames} å¸§")
    print(f"   - è¯»å–æ€»æ—¶é—´: {read_total_time:.2f} ç§’")
    print(f"   - å®é™…è¯»å–FPS: {read_fps:.2f} fps")

    # 2. æ¨ç†æ€§èƒ½ï¼ˆä»…ç»Ÿè®¡æœ‰æœ‰æ•ˆæ¨ç†çš„æƒ…å†µï¼‰
    if infer_start_time is not None and infer_total_frames > 0:
        infer_total_wall_time = time.time() - infer_start_time  # æ¨ç†é˜¶æ®µå¢™é’Ÿæ—¶é—´
        infer_fps = infer_total_frames / infer_total_wall_time  # å®é™…æ¨ç†FPS
        device_utilization = (total_infer_compute_time / (NUM_DEVICES * infer_total_wall_time)) * 100  # è®¾å¤‡åˆ©ç”¨ç‡
        parallel_speedup = (total_infer_compute_time / NUM_DEVICES) / infer_total_wall_time  # å¹¶è¡ŒåŠ é€Ÿæ¯”

        print(f"\n2. æ¨ç†æ€§èƒ½ï¼ˆ{NUM_DEVICES} è®¾å¤‡å¹¶è¡Œï¼‰")
        print(f"   - æ€»æ¨ç†å¸§æ•°: {infer_total_frames} å¸§")
        print(f"   - æ¨ç†å¢™é’Ÿæ—¶é—´: {infer_total_wall_time:.2f} ç§’")
        print(f"   - æ¨ç†è®¡ç®—æ€»è€—æ—¶ï¼ˆç´¯åŠ ï¼‰: {total_infer_compute_time:.2f} ç§’")
        print(f"   - å®é™…æ¨ç†FPS: {infer_fps:.2f} fps")
        print(f"   - è®¾å¤‡å¹³å‡åˆ©ç”¨ç‡: {device_utilization:.1f}%")
        print(f"   - å¹¶è¡ŒåŠ é€Ÿæ¯”: {parallel_speedup:.2f}x")
    else:
        print(f"\n2. æ¨ç†æ€§èƒ½")
        print(f"   - æœªå®Œæˆæœ‰æ•ˆæ¨ç†ï¼ˆå¯èƒ½è®¾å¤‡åˆå§‹åŒ–å¤±è´¥æˆ–æ— å¸§è¾“å…¥ï¼‰")

    # 3. æ•´ä½“æ€§èƒ½ç“¶é¢ˆåˆ†æ
    print(f"\n3. ç“¶é¢ˆåˆ†æ")
    if read_fps < TARGET_FPS * 0.9:
        print(f"   âš ï¸  æ‘„åƒå¤´è¯»å–FPSï¼ˆ{read_fps:.2f}ï¼‰ä½äºç›®æ ‡ï¼ˆ{TARGET_FPS}ï¼‰ï¼Œè¯»å–ä¸ºç“¶é¢ˆ")
    elif infer_start_time is not None and infer_fps < read_fps * 0.9:
        print(f"   âš ï¸  æ¨ç†FPSï¼ˆ{infer_fps:.2f}ï¼‰ä½äºè¯»å–FPSï¼ˆ{read_fps:.2f}ï¼‰ï¼Œæ¨ç†ä¸ºç“¶é¢ˆ")
    else:
        print(f"   âœ… æ€§èƒ½åŒ¹é…ï¼šæ¨ç†FPSï¼ˆ{infer_fps:.2f}ï¼‰â‰¥ è¯»å–FPSï¼ˆ{read_fps:.2f}ï¼‰ï¼Œæ— æ˜æ˜¾ç“¶é¢ˆ")

    total_time = time.time() - total_start_time
    print(f"\n4. æ•´ä½“è€—æ—¶: {total_time:.2f} ç§’")
    print("="*60)

if __name__ == "__main__":
    # Windowsç³»ç»Ÿéœ€å¼ºåˆ¶ä½¿ç”¨spawnå¯åŠ¨æ–¹å¼ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
    mp.set_start_method("spawn", force=True)
    main()