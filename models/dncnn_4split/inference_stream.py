import os
import time
import cv2
import numpy as np
import multiprocessing as mp
from tqdm import tqdm
import queue
from hailo_platform import (
    HEF,
    ConfigureParams,
    Device,
    FormatType,
    HailoSchedulingAlgorithm,
    HailoStreamInterface,
    InferVStreams,
    InputVStreamParams,
    OutputVStreamParams,
    VDevice,
)

# -------------------------- æ ¸å¿ƒé…ç½®å‚æ•° --------------------------
# æ‘„åƒå¤´å‚æ•°
CAMERA_DEVICE_PATH = "/dev/video20"  # æ‘„åƒå¤´è®¾å¤‡è·¯å¾„ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
TARGET_RESOLUTION = (960, 720)       # ç›®æ ‡åˆ†è¾¨ç‡ (width, height)
TARGET_FPS = 20                      # ç›®æ ‡å¸§ç‡
VIDEO_FORMAT = cv2.VideoWriter_fourcc(*"MJPG")  # æ‘„åƒå¤´æ ¼å¼ï¼ˆMJPGæ”¯æŒé«˜å¸§ç‡ï¼‰

# æ¨ç†å‚æ•°
HEF_PATH = "/home/firefly/Denoising-rk3588J/models/dncnn_4split/dncnn_4split_16pad.hef"  # Hailoæ¨¡å‹è·¯å¾„
BATCH_SIZE = 1                        # å•è®¾å¤‡æ‰¹æ¬¡å¤§å°ï¼ˆå¹³è¡¡å®æ—¶æ€§ä¸æ•ˆç‡ï¼‰
INPUT_SHAPE = (3, 720, 960)          # æ¨¡å‹è¾“å…¥å½¢çŠ¶ (channel, height, width)
NUM_DEVICES = 2                       # å¯ç”¨çš„HailoåŠ é€Ÿæ£’æ•°é‡
QUEUE_MAX_SIZE = 100                   # ä»»åŠ¡é˜Ÿåˆ—æœ€å¤§ç¼“å­˜ï¼ˆé¿å…å¸§å †ç§¯ï¼‰
RUN_DURATION = 10                     # æµ‹è¯•è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼Œå¯ä¿®æ”¹ï¼‰

# -------------------------- å¸§é¢„å¤„ç†ï¼ˆé€‚é…æ‘„åƒå¤´è¾“å…¥ï¼‰ --------------------------
def process_frame(frame):
    """
    å¤„ç†æ‘„åƒå¤´BGRå¸§ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ï¼ˆRGB+CHW+float32ï¼‰
    :param frame: cv2è¯»å–çš„BGRå¸§ï¼ˆHWCæ ¼å¼ï¼‰
    :return: é¢„å¤„ç†åçš„æ•°æ®ï¼ˆCHWæ ¼å¼ï¼‰ã€é¢„å¤„ç†è€—æ—¶ã€è°ƒæ•´ååŸå§‹BGRå¸§ï¼ˆç”¨äºæ‹¼æ¥ï¼‰
    """
    start_time = time.time()
    
    # 1. è°ƒæ•´åˆ†è¾¨ç‡ï¼ˆç¡®ä¿ä¸ç›®æ ‡ä¸€è‡´ï¼Œåç»­æ‹¼æ¥æ—¶å°ºå¯¸ç»Ÿä¸€ï¼‰
    frame_resized = cv2.resize(
        frame, 
        dsize=TARGET_RESOLUTION, 
        interpolation=cv2.INTER_LANCZOS4  # é«˜è´¨é‡æ’å€¼ï¼ˆä¸åŸä»£ç PIL.LANCZOSå¯¹åº”ï¼‰
    )
    
    # 2. BGRè½¬RGBï¼ˆcv2é»˜è®¤BGRï¼Œæ¨¡å‹éœ€è¦RGBï¼‰
    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)

    # 3. æ ¼å¼è½¬æ¢ï¼šHWC -> CHWï¼Œ dtype -> float32
    # frame_chw = frame_rgb.transpose(2, 0, 1)  # (H,W,C) â†’ (C,H,W)
    frame_float = frame_rgb.astype(np.float32)
    
    process_time = time.time() - start_time
    return frame_float, process_time

# -------------------------- è®¾å¤‡åˆå§‹åŒ–ï¼ˆå¤ç”¨åŸæ¨ç†é€»è¾‘ï¼‰ --------------------------
def init_device(hef_path, device_id):
    """åˆå§‹åŒ–å•ä¸ªHailoè®¾å¤‡å¹¶åŠ è½½æ¨¡å‹ï¼Œä¸åŸæ¨ç†ä»£ç é€»è¾‘ä¸€è‡´"""
    device_ids = Device.scan()
    if len(device_ids) <= device_id:
        raise RuntimeError(f"è®¾å¤‡ID {device_id} ä¸å­˜åœ¨ï¼Œä»…æ£€æµ‹åˆ° {len(device_ids)} ä¸ªè®¾å¤‡")
    
    print(f"åˆå§‹åŒ–è®¾å¤‡ {device_id}ï¼ˆç¡¬ä»¶ID: {device_ids[device_id]}ï¼‰...")
    
    # åˆ›å»ºè®¾å¤‡å‚æ•°ï¼ˆPCIeæ¥å£ï¼‰
    vdevice_params = VDevice.create_params()
    vdevice_params.scheduling_algorithm = HailoSchedulingAlgorithm.NONE
    vdevice_params.device_ids.append(device_id)
    target = VDevice(params=vdevice_params)
    
    # åŠ è½½HEFæ¨¡å‹
    hef = HEF(hef_path)
    
    # é…ç½®ç½‘ç»œç»„
    configure_params = ConfigureParams.create_from_hef(hef=hef, interface=HailoStreamInterface.PCIe)
    network_groups = target.configure(hef, configure_params)
    network_group = network_groups[0]
    network_group_params = network_group.create_params()
    
    # åˆ›å»ºè¾“å…¥/è¾“å‡ºæµå‚æ•°ï¼ˆè¾“å…¥float32ï¼Œè¾“å‡ºuint8ï¼‰
    input_vstreams_params = InputVStreamParams.make(network_group, quantized=False, format_type=FormatType.FLOAT32)
    output_vstreams_params = OutputVStreamParams.make(network_group, quantized=True, format_type=FormatType.UINT8)
    
    # è·å–æµä¿¡æ¯
    input_vstream_info = hef.get_input_vstream_infos()[0]
    output_vstream_info = hef.get_output_vstream_infos()[0]
    
    device_info = {
        "target": target,
        "hef": hef,
        "network_group": network_group,
        "network_group_params": network_group_params,
        "input_vstreams_params": input_vstreams_params,
        "output_vstreams_params": output_vstreams_params,
        "input_vstream_info": input_vstream_info,
        "output_vstream_info": output_vstream_info,
        "device_id": device_id
    }
    
    print(f"è®¾å¤‡ {device_id} åˆå§‹åŒ–å®Œæˆ | è¾“å…¥å½¢çŠ¶: {input_vstream_info.shape} | è¾“å‡ºå½¢çŠ¶: {output_vstream_info.shape}")
    return device_info

# -------------------------- æ¨ç†å‡½æ•°ï¼ˆå¤ç”¨åŸé€»è¾‘ï¼‰ --------------------------
def run_inference(device, input_batch):
    """åœ¨å•ä¸ªè®¾å¤‡ä¸Šè¿è¡Œæ¨ç†ï¼Œè¿”å›æ¨ç†ç»“æœä¸è€—æ—¶"""
    network_group = device["network_group"]
    input_vstreams_params = device["input_vstreams_params"]
    output_vstreams_params = device["output_vstreams_params"]
    network_group_params = device["network_group_params"]
    input_vstream_info = device["input_vstream_info"]

    start_time = time.time()
    with InferVStreams(network_group, input_vstreams_params, output_vstreams_params) as infer_pipeline:
        with network_group.activate(network_group_params):
            input_data = {input_vstream_info.name: input_batch}
            infer_results = infer_pipeline.infer(input_data)
    
    inference_time = time.time() - start_time
    output_tensor = infer_results[device["output_vstream_info"].name]

    return output_tensor, inference_time

def split_and_stack(batch_tensor):
    """
    å°†å½¢çŠ¶ä¸º[1, 720, 960, 3]çš„å›¾åƒæ•°ç»„åˆ†å‰²ä¸º4å¼ å­å›¾å¹¶å †å ä¸º[4, 360, 480, 3]
    
    å‚æ•°:
        batch_tensor: å½¢çŠ¶ä¸º[1, 720, 960, 3]çš„numpyæ•°ç»„
        
    è¿”å›:
        å½¢çŠ¶ä¸º[4, 360, 480, 3]çš„numpyæ•°ç»„
    """
    # æ£€æŸ¥è¾“å…¥å½¢çŠ¶æ˜¯å¦æ­£ç¡®
    if batch_tensor.shape != (1, 720, 960, 3):
        raise ValueError(f"è¾“å…¥æ•°ç»„å½¢çŠ¶å¿…é¡»ä¸º[1, 720, 960, 3], å®é™…è¾“å…¥æ•°ç»„å½¢çŠ¶ä¸º{batch_tensor.shape}")
    
    # ç§»é™¤æ‰¹æ¬¡ç»´åº¦ï¼Œå¾—åˆ°[720, 960, 3]
    image = batch_tensor[0]
    
    # è®¡ç®—å­å›¾çš„é«˜åº¦å’Œå®½åº¦
    sub_height = 720 // 2
    sub_width = 960 // 2
    
    # åˆ†å‰²ä¸º4ä¸ªå­å›¾
    # å·¦ä¸Šè§’
    sub1 = image[:sub_height+16, :sub_width+16, :]
    # å·¦ä¸‹è§’
    sub2 = image[sub_height-16:, :sub_width+16, :]
    # å³ä¸Šè§’
    sub3 = image[:sub_height+16, sub_width-16:, :]
    # å³ä¸‹è§’
    sub4 = image[sub_height-16:, sub_width-16:, :]
    
    # å †å æˆ[4, 360, 480, 3]çš„æ•°ç»„
    stacked = np.stack([sub1, sub2, sub3, sub4], axis=0)
    
    return stacked

def stack_to_original(sub_images):
    """
    å°†å½¢çŠ¶ä¸º[4, 360, 480, 3]çš„å­å›¾æ•°ç»„æ‹¼æ¥ä¸ºåŸå§‹å›¾åƒ[1, 720, 960, 3]
    
    å‚æ•°:
        sub_images: å½¢çŠ¶ä¸º[4, 360, 480, 3]çš„numpyæ•°ç»„ï¼ŒåŒ…å«4ä¸ªå­å›¾
                    é¡ºåºåº”ä¸º[å·¦ä¸Š, å·¦ä¸‹, å³ä¸Š, å³ä¸‹]
        
    è¿”å›:
        å½¢çŠ¶ä¸º[1, 720, 960, 3]çš„numpyæ•°ç»„ï¼ŒåŸå§‹å›¾åƒ
    """
    # æ£€æŸ¥è¾“å…¥å½¢çŠ¶æ˜¯å¦æ­£ç¡®
    if sub_images.shape != (4, 376, 496, 3):
        raise ValueError(f"è¾“å…¥æ•°ç»„å½¢çŠ¶å¿…é¡»ä¸º[4, 360, 480, 3], å®é™…å½¢çŠ¶ä¸º{sub_images.shape}")
    
    # æå–4ä¸ªå­å›¾
    sub1, sub2, sub3, sub4 = sub_images[0], sub_images[1], sub_images[2], sub_images[3]
    
    # æ°´å¹³æ‹¼æ¥ç¬¬ä¸€è¡Œï¼ˆä¸ŠåŠéƒ¨åˆ†ï¼‰
    top_row = np.concatenate([sub1[:360,:480,:], sub3[:360,16:]], axis=1)
    
    # æ°´å¹³æ‹¼æ¥ç¬¬äºŒè¡Œï¼ˆä¸‹åŠéƒ¨åˆ†ï¼‰
    bottom_row = np.concatenate([sub2[16:,:480,:], sub4[16:, 16:,:]], axis=1)
    
    # å‚ç›´æ‹¼æ¥ä¸¤è¡Œï¼Œå¾—åˆ°å®Œæ•´å›¾åƒ
    full_image = np.concatenate([top_row, bottom_row], axis=0)
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ï¼Œå½¢çŠ¶å˜ä¸º[1, 720, 960, 3]
    return np.expand_dims(full_image, axis=0)

# -------------------------- å·¥ä½œè¿›ç¨‹ï¼ˆç§»é™¤å›¾åƒä¿å­˜ï¼Œä¸“æ³¨æ¨ç†ï¼‰ --------------------------
def worker_process(device_id, task_queue, result_queue, hef_path):
    """
    è®¾å¤‡å·¥ä½œè¿›ç¨‹ï¼šæ¥æ”¶æ‘„åƒå¤´å¸§æ‰¹æ¬¡ â†’ æ¨ç† â†’ è¿”å›ç»“æœï¼ˆæ— å›¾åƒä¿å­˜ï¼‰
    :param task_queue: ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå…ƒç´ ï¼š(batch_tensor, actual_batch_size, batch_index)ï¼‰
    :param result_queue: ç»“æœé˜Ÿåˆ—ï¼ˆå…ƒç´ ï¼š(batch_index, actual_batch_size, infer_time)ï¼‰
    """
    try:
        device = init_device(hef_path, device_id)
        print(f"è®¾å¤‡ {device_id} å·¥ä½œè¿›ç¨‹å¯åŠ¨ï¼ˆPID: {os.getpid()}ï¼‰")
        
        while True:
            task = task_queue.get()
            if task is None:  # ç»ˆæ­¢ä¿¡å·
                break
            batch_tensor, actual_batch_size, batch_index = task
            batch_tensor = split_and_stack(batch_tensor)
            # æ‰§è¡Œæ¨ç†ï¼Œè·å–å»å™ªåå¸§
            output_tensor, infer_time = run_inference(device, batch_tensor)
            # æ‹¼å›åŸå›¾
            output_tensor = stack_to_original(output_tensor)
            # å›ä¼ å¤„ç†åå¸§ï¼ˆoutput_tensorä¸º[1, 720, 960, 3]ï¼Œfloat/uint8ï¼‰
            result_queue.put((batch_index, actual_batch_size, infer_time, output_tensor))
    
    except Exception as e:
        print(f"è®¾å¤‡ {device_id} å·¥ä½œè¿›ç¨‹å‡ºé”™: {str(e)}")
    finally:
        # é‡Šæ”¾è®¾å¤‡èµ„æº
        if "device" in locals():
            device["target"].release()
        print(f"è®¾å¤‡ {device_id} å·¥ä½œè¿›ç¨‹é€€å‡º")

# -------------------------- ä¸»æµç¨‹ï¼ˆæ‘„åƒå¤´è¯»å–+å®æ—¶æ¨ç†+FPSç»Ÿè®¡ï¼‰ --------------------------
def main():
    total_start_time = time.time()
    print("="*60)
    print(f"å¼€å§‹å®æ—¶æ¨ç†æµ‹è¯• | ç›®æ ‡: {TARGET_RESOLUTION[0]}Ã—{TARGET_RESOLUTION[1]} @ {TARGET_FPS}fps | è¿è¡Œæ—¶é•¿: {RUN_DURATION}s")
    print(f"è®¾å¤‡æ•°é‡: {NUM_DEVICES} | æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} | æ¨¡å‹è·¯å¾„: {HEF_PATH}")
    print("="*60)

    # -------------------------- 1. åˆå§‹åŒ–è¿›ç¨‹ä¸é˜Ÿåˆ— --------------------------
    # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ¯ä¸ªè®¾å¤‡ä¸€ä¸ªï¼‰ï¼šç¼“å­˜å¾…æ¨ç†çš„å¸§æ‰¹æ¬¡
    task_queues = [mp.Queue(maxsize=QUEUE_MAX_SIZE) for _ in range(NUM_DEVICES)]
    # ç»“æœé˜Ÿåˆ—ï¼šæ¥æ”¶æ¨ç†ç»Ÿè®¡ä¿¡æ¯
    result_queue = mp.Queue()
    
    # å¯åŠ¨å·¥ä½œè¿›ç¨‹
    processes = []
    for device_id in range(NUM_DEVICES):
        p = mp.Process(
            target=worker_process,
            args=(device_id, task_queues[device_id], result_queue, HEF_PATH)
        )
        p.start()
        processes.append(p)
    time.sleep(2)  # ç­‰å¾…è®¾å¤‡åˆå§‹åŒ–å®Œæˆ

    # -------------------------- 2. åˆå§‹åŒ–æ‘„åƒå¤´ --------------------------
    cap = cv2.VideoCapture(CAMERA_DEVICE_PATH)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´è®¾å¤‡: {CAMERA_DEVICE_PATH}")
    
    # è®¾ç½®æ‘„åƒå¤´å‚æ•°ï¼ˆMJPGæ ¼å¼æ”¯æŒé«˜å¸§ç‡ï¼‰
    cap.set(cv2.CAP_PROP_FOURCC, VIDEO_FORMAT)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, TARGET_RESOLUTION[0])
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, TARGET_RESOLUTION[1])
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
    
    # éªŒè¯å‚æ•°æ˜¯å¦è®¾ç½®æˆåŠŸï¼ˆéƒ¨åˆ†æ‘„åƒå¤´å¯èƒ½ä¸æ”¯æŒç›®æ ‡é…ç½®ï¼‰
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    actual_fps = cap.get(cv2.CAP_PROP_FPS)
    print(f"\næ‘„åƒå¤´å‚æ•°éªŒè¯ | å®é™…åˆ†è¾¨ç‡: {actual_width}Ã—{actual_height} | å®é™…å¸§ç‡: {actual_fps:.1f}fps")
    if (actual_width, actual_height) != TARGET_RESOLUTION:
        print(f"âš ï¸  æ‘„åƒå¤´ä¸æ”¯æŒ {TARGET_RESOLUTION[0]}Ã—{TARGET_RESOLUTION[1]}ï¼Œå°†ä½¿ç”¨å®é™…åˆ†è¾¨ç‡ {actual_width}Ã—{actual_height}")

    # -------------------------- 3. åˆå§‹åŒ–ç»Ÿè®¡å˜é‡ --------------------------
    read_total_frames = 0          # æ‘„åƒå¤´è¯»å–çš„æ€»å¸§æ•°
    infer_total_frames = 0         # æˆåŠŸæ¨ç†çš„æ€»å¸§æ•°
    read_start_time = time.time()  # æ‘„åƒå¤´è¯»å–å¼€å§‹æ—¶é—´
    infer_start_time = None        # æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç¬¬ä¸€ä¸ªæ‰¹æ¬¡å‘é€æ—¶è®°å½•ï¼‰
    total_infer_compute_time = 0   # æ¨ç†è®¡ç®—æ€»è€—æ—¶ï¼ˆæ‰€æœ‰è®¾å¤‡ç´¯åŠ ï¼‰
    batch_index = 0                # æ‰¹æ¬¡ç´¢å¼•ï¼ˆç”¨äºåŒ¹é…ä»»åŠ¡ä¸ç»“æœï¼‰
    device_buffers = [[] for _ in range(NUM_DEVICES)]  # å„è®¾å¤‡çš„å¸§ç¼“å­˜ï¼ˆç§¯ç´¯æ‰¹æ¬¡ï¼‰
    # æ–°å¢ï¼šç”¨äºå­˜å‚¨å¾…æ˜¾ç¤ºå¸§çš„é˜Ÿåˆ—
    display_queue = []

    # -------------------------- 4. å®æ—¶è¯»å–+æ¨ç†å¾ªç¯ --------------------------
    print(f"\nå¼€å§‹è¯»å–æ‘„åƒå¤´å¸§ï¼ˆæŒ‰ 'q' æå‰é€€å‡ºï¼‰...")
    # æ–°å¢ï¼šä¸»å¾ªç¯åŒæ—¶å¤„ç†æ‘„åƒå¤´è¯»å–å’Œæ¨ç†ç»“æœæ˜¾ç¤º
    # while (time.time() - read_start_time) < RUN_DURATION:
    while True:
        # è¯»å–æ‘„åƒå¤´å¸§
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸  æ— æ³•è¯»å–æ‘„åƒå¤´å¸§ï¼Œé€€å‡ºå¾ªç¯")
            break

        read_total_frames += 1
        current_time = time.time()

        # é¢„å¤„ç†å¸§ï¼ˆBGRâ†’RGBâ†’CHWâ†’float32ï¼‰
        frame_processed, _ = process_frame(frame)

        # åˆ†é…å¸§åˆ°è®¾å¤‡ç¼“å­˜ï¼ˆè½®è¯¢åˆ†é…ï¼Œå‡è¡¡è´Ÿè½½ï¼‰
        target_device_id = read_total_frames % NUM_DEVICES
        device_buffers[target_device_id].append(frame_processed)

        # å½“ç¼“å­˜è¾¾åˆ°æ‰¹æ¬¡å¤§å°æ—¶ï¼Œå‘é€æ¨ç†ä»»åŠ¡
        if len(device_buffers[target_device_id]) >= BATCH_SIZE:
            batch_frames = device_buffers[target_device_id][:BATCH_SIZE]
            actual_batch_size = len(batch_frames)
            if actual_batch_size < BATCH_SIZE:
                pad_size = BATCH_SIZE - actual_batch_size
                batch_frames += [np.zeros_like(batch_frames[0]) for _ in range(pad_size)]
            batch_tensor = np.stack(batch_frames, axis=0)
            try:
                task_queues[target_device_id].put(
                    (batch_tensor, actual_batch_size, batch_index),
                    block=False
                )
                batch_index += 1
                if infer_start_time is None:
                    infer_start_time = current_time
                print(f"ğŸ“¤ è®¾å¤‡ {target_device_id} å‘é€æ‰¹æ¬¡ {batch_index-1}ï¼ˆæœ‰æ•ˆå¸§: {actual_batch_size}ï¼‰", end="\r")
            except mp.Queue.Full:
                print(f"âš ï¸  è®¾å¤‡ {target_device_id} ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå½“å‰æ‰¹æ¬¡", end="\r")
                
            device_buffers[target_device_id] = device_buffers[target_device_id][BATCH_SIZE:]

        # æ–°å¢ï¼šå®æ—¶è·å–æ¨ç†ç»“æœå¹¶å±•ç¤º
        # å°è¯•éé˜»å¡è·å–ç»“æœé˜Ÿåˆ—ï¼ˆé¿å…é˜»å¡ä¸»å¾ªç¯ï¼‰
        try:
            while True:
                batch_idx, actual_frames, infer_time, output_tensor = result_queue.get(block=False)
                infer_total_frames += actual_frames
                total_infer_compute_time += infer_time
                # output_tensor: [1, 720, 960, 3]ï¼Œå¦‚float32/uint8ï¼Œéœ€è½¬ä¸ºuint8å’ŒBGR
                frame_to_show = output_tensor[0]
                if frame_to_show.dtype != np.uint8:
                    frame_to_show = np.clip(frame_to_show, 0, 255).astype(np.uint8)
                # RGB->BGR
                #frame_to_show = cv2.cvtColor(frame_to_show, cv2.COLOR_RGB2BGR)
                cv2.imshow("Denoised Stream", frame_to_show)
                cv2.imwrite("video_frame_test.jpg", frame_to_show)
                # æŒ‰ 'q' é”®æå‰é€€å‡º
                if cv2.waitKey(1) & 0xFF == ord("q"):
                    print("\nğŸ›‘ ç”¨æˆ·æŒ‰ä¸‹ 'q' é”®ï¼Œæå‰é€€å‡º")
                    raise KeyboardInterrupt
        except KeyboardInterrupt:
            break
        except Exception:
            pass  # é˜Ÿåˆ—ä¸ºç©ºæ—¶ç»§ç»­ä¸»å¾ªç¯

    # -------------------------- 5. å¤„ç†å‰©ä½™å¸§ï¼ˆç¼“å­˜ä¸­æœªå‘é€çš„å¸§ï¼‰ --------------------------
    print(f"\n\nå¤„ç†ç¼“å­˜ä¸­å‰©ä½™çš„å¸§...")
    for device_id in range(NUM_DEVICES):
        remaining_frames = device_buffers[device_id]
        if len(remaining_frames) == 0:
            continue
        
        # å¤„ç†å‰©ä½™å¸§ï¼ˆä¸è¶³æ‰¹æ¬¡å¤§å°æ—¶è¡¥é›¶ï¼‰
        actual_batch_size = len(remaining_frames)
        if actual_batch_size < BATCH_SIZE:
            pad_size = BATCH_SIZE - actual_batch_size
            remaining_frames += [np.zeros_like(remaining_frames[0]) for _ in range(pad_size)]
        
        batch_tensor = np.stack(remaining_frames, axis=0)
        try:
            task_queues[device_id].put((batch_tensor, actual_batch_size, batch_index), block=True, timeout=5)
            batch_index += 1
            print(f"ğŸ“¤ è®¾å¤‡ {device_id} å‘é€å‰©ä½™æ‰¹æ¬¡ {batch_index-1}ï¼ˆæœ‰æ•ˆå¸§: {actual_batch_size}ï¼‰")
        except mp.Queue.Full:
            print(f"âš ï¸  è®¾å¤‡ {device_id} é˜Ÿåˆ—æ»¡ï¼Œæ— æ³•å‘é€å‰©ä½™ {actual_batch_size} å¸§")

    # -------------------------- 6. å‘é€ç»ˆæ­¢ä¿¡å·å¹¶æ”¶é›†ç»“æœ --------------------------
    # å‘æ‰€æœ‰å·¥ä½œè¿›ç¨‹å‘é€ç»ˆæ­¢ä¿¡å·
    for q in task_queues:
        q.put(None)


    # -------------------------- 7. é‡Šæ”¾èµ„æº --------------------------
    cap.release()
    cv2.destroyAllWindows()
    for p in processes:
        p.join(timeout=10)
        print(f"ğŸ”š è®¾å¤‡è¿›ç¨‹ {p.pid} ")


if __name__ == "__main__":
    # Windowsç³»ç»Ÿéœ€å¼ºåˆ¶ä½¿ç”¨spawnå¯åŠ¨æ–¹å¼ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
    mp.set_start_method("spawn", force=True)
    main()
